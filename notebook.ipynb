{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "First we load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"ml-25m/ratings.csv\")\n",
    "movies_df = pd.read_csv(\"ml-25m/movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000095 entries, 0 to 25000094\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   userId     int64  \n",
      " 1   movieId    int64  \n",
      " 2   rating     float64\n",
      " 3   timestamp  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 762.9 MB\n"
     ]
    }
   ],
   "source": [
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147880044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147868828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147878820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1088</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1147868495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1175</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1217</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147878326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1237</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147868839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1250</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1147868414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      296     5.0  1147880044\n",
       "1       1      306     3.5  1147868817\n",
       "2       1      307     5.0  1147868828\n",
       "3       1      665     5.0  1147878820\n",
       "4       1      899     3.5  1147868510\n",
       "5       1     1088     4.0  1147868495\n",
       "6       1     1175     3.5  1147868826\n",
       "7       1     1217     3.5  1147878326\n",
       "8       1     1237     5.0  1147868839\n",
       "9       1     1250     4.0  1147868414"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62423 entries, 0 to 62422\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  62423 non-null  int64 \n",
      " 1   title    62423 non-null  object\n",
      " 2   genres   62423 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Movies without a genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "nogenres_indexes = movies_df.index[movies_df['genres'] == '(no genres listed)'].tolist()\n",
    "movieId_todelete = movies_df.iloc[nogenres_indexes]['movieId'].to_numpy()\n",
    "ratings_df.drop(ratings_df[ratings_df['movieId'].isin(movieId_todelete)].index, inplace=True)\n",
    "ratings_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies_df.drop(index=nogenres_indexes,inplace=True)\n",
    "#movies_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62423 entries, 0 to 62422\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  62423 non-null  int64 \n",
      " 1   title    62423 non-null  object\n",
      " 2   genres   62423 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_genres = {}\n",
    "for e in movies_df.itertuples():\n",
    "    genres_in_row = e[-1].split('|')\n",
    "    for genre in genres_in_row:\n",
    "        if genre in p_genres:\n",
    "            p_genres[genre] += 1\n",
    "        else:\n",
    "            p_genres[genre] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adventure': 4145,\n",
       " 'Animation': 2929,\n",
       " 'Children': 2935,\n",
       " 'Comedy': 16870,\n",
       " 'Fantasy': 2731,\n",
       " 'Romance': 7719,\n",
       " 'Drama': 25606,\n",
       " 'Action': 7348,\n",
       " 'Crime': 5319,\n",
       " 'Thriller': 8654,\n",
       " 'Horror': 5989,\n",
       " 'Mystery': 2925,\n",
       " 'Sci-Fi': 3595,\n",
       " 'IMAX': 195,\n",
       " 'Documentary': 5605,\n",
       " 'War': 1874,\n",
       " 'Musical': 1054,\n",
       " 'Western': 1399,\n",
       " 'Film-Noir': 353,\n",
       " '(no genres listed)': 5062}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons observer qu'il existe un imbalance en terme de genres de film avec énormement plus de films de Drama que d'autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162541"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = ratings_df[\"userId\"].unique()\n",
    "nb_user = len(user_ids)\n",
    "nb_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_by_user_dict = dict(tuple(ratings_df.groupby('userId')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162541/162541 [05:27<00:00, 495.65it/s]\n",
      "C:\\Users\\ferdi\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(102460,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "ratings_by_user = []\n",
    "for user_id in tqdm.tqdm(user_ids):\n",
    "    \n",
    "    ratings_of_user = ratings_by_user_dict[user_id]\n",
    "    ratings_of_user.sort_values(by=\"timestamp\", inplace=True, ignore_index=True)\n",
    "    \n",
    "    number_of_ratings = len(ratings_of_user)\n",
    "    ratings_of_user = ratings_of_user.to_numpy()\n",
    "    \n",
    "    # We only keep users with more than 50 ratings\n",
    "    if number_of_ratings >= 50:\n",
    "        \n",
    "        ## We crop to have 25 ratings/frame\n",
    "        if number_of_ratings % 25 != 0:\n",
    "            round_number = number_of_ratings % 25\n",
    "            ratings_of_user = ratings_of_user[:-round_number]\n",
    "            number_of_ratings = ratings_of_user.shape[0]\n",
    "        \n",
    "\n",
    "        dividing_size = number_of_ratings / 25\n",
    "        \n",
    "        user_frames = np.split(ratings_of_user, dividing_size)\n",
    "        \n",
    "        ratings_by_user.append(np.expand_dims(np.array(user_frames), axis=-1))\n",
    "\n",
    "ratings_by_user = np.array(ratings_by_user)\n",
    "    \n",
    "ratings_by_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102460"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings_by_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 25, 4, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_by_user[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 25, 4, 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_by_user[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_height=ratings_by_user[0].shape[1]\n",
    "in_width=ratings_by_user[0].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"user_frames_divided.npy\", ratings_by_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max ID of movie:  209171\n"
     ]
    }
   ],
   "source": [
    "column_movieId = movies_df[\"movieId\"]\n",
    "print(\"Max ID of movie: \", column_movieId.max())\n",
    "id_list = column_movieId.to_numpy()\n",
    "\n",
    "id_dictionnary = sorted(set(id_list))\n",
    "\n",
    "id_to_index =  {u:i for i, u in enumerate(id_dictionnary)}\n",
    "index_to_id = list(id_dictionnary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Convolutional Tensor-Train LSTM Recommendation Net  \n",
    "The model was inspired by Covolutional Click Prediction Model (CCPM)  \n",
    " We want to vase our recommendation on previous recommendation we made. We want to add the sequential information  \n",
    "Therefore, we replace the second convolution by a Convolutional Tensor Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.convlstmnet import ConvLSTMNet\n",
    "from torch.nn import Conv2d, AdaptiveMaxPool2d, Linear, Tanh, ReLU, MaxPool2d, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters for the CTLRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size=len(movies_df) # Number of movies\n",
    "inputs_channels=1# To define ==> 2\n",
    "lstm_input_channels=3\n",
    "cell = \"convttlstm\"\n",
    "order = 3\n",
    "steps = 3\n",
    "rank = 8\n",
    "kernel_size = 5\n",
    "lr=1e-3\n",
    "output_sigmoid = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_size_w=in_height//2\n",
    "padding_size_h=in_width//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctln_model = ConvLSTMNet(\n",
    "        # input to the model\n",
    "        input_channels = lstm_input_channels, \n",
    "        # architecture of the model\n",
    "        layers_per_block = (3, 3, 3, 3), \n",
    "        hidden_channels = (32, 48, 48, 32), \n",
    "        skip_stride = 2,\n",
    "        # parameters of convolutional tensor-train layers\n",
    "        cell = cell, cell_params = {\"order\": order,\n",
    "        \"steps\": steps, \"rank\": rank},\n",
    "        # parameters of convolutional operations\n",
    "        kernel_size = kernel_size, bias = True,\n",
    "        # output function and output format\n",
    "        output_sigmoid = output_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTLRNet(nn.Module):\n",
    "    def __init__(self, inputs_channels, output_size):\n",
    "        super(CTLRNet, self).__init__()\n",
    "        \n",
    "        self.inputs_channels = inputs_channels\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.conv1 = Conv2d(in_channels=inputs_channels, out_channels=lstm_input_channels,\n",
    "                       padding=(padding_size_h,padding_size_h), kernel_size=(3,3))\n",
    "        self.pool1 = AdaptiveMaxPool2d(output_size=(in_height, in_width))\n",
    "        self.tanh = Tanh()\n",
    "        self.convttlstm = ctln_model\n",
    "        self.pool2 = MaxPool2d(2) # Padding ?\n",
    "        self.flatten = Flatten()\n",
    "        self.linear = Linear(in_features=72, out_features=output_size)\n",
    "        self.relu = ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.tanh(x)\n",
    "        \n",
    "        ## To study exactly\n",
    "        ## uwu ?\n",
    "        x = torch.unsqueeze(x, dim=0)\n",
    "        x = self.convttlstm(x, input_frames = inputs.shape[1], future_frames = 1, output_frames = 1)\n",
    "        x = torch.squeeze(x, dim=0)\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        y = self.relu(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CTLRNet(inputs_channels, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_test_data = torch.from_numpy(ratings_by_user[0]).permute([0,3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 25, 4])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 62423])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(quick_test_data.float()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(ratings_by_user)\n",
    "\n",
    "data_samples = ratings_by_user.shape[0]\n",
    "\n",
    "train_size = math.ceil(data_samples * 0.70)\n",
    "test_size = data_samples - train_size\n",
    "\n",
    "train_data = ratings_by_user[train_size:]\n",
    "test_data = ratings_by_user[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_x_y(data, p=0.25):\n",
    "    \"\"\"\n",
    "    Split and construct a frame into an input and an output\n",
    "    parameters data: (nb_frames, c, h, w0)\n",
    "    return: (nb_frames, c, h, w0), (nb_movies)\n",
    "    \"\"\"\n",
    "    data = torch.from_numpy(data).permute([0,3,1,2])\n",
    "    data_frames = data.shape[0]\n",
    "    X_size = math.ceil(data_frames * (1-p))\n",
    "    Y_data_size = data_frames - X_size\n",
    "    \n",
    "    \n",
    "    X = data[:X_size]\n",
    "    Y_data = data[Y_data_size:]\n",
    "    \n",
    "    y = np.zeros(output_size)\n",
    "    \n",
    "    #print()\n",
    "    \n",
    "    #y[Y_data[...,1]] = Y_data[...,2]\n",
    "    \n",
    "    for frame in Y_data:\n",
    "        for row in frame[0]:\n",
    "            y[id_to_index[int(row[1])]] = row[2]\n",
    "    \n",
    "    return X, torch.from_numpy(y.reshape(1,-1)).double()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_loss(y_pred, y_true):\n",
    "    return F.l1_loss(y_pred, y_true, reduction = \"mean\") + F.mse_loss(y_pred, y_true, reduction = \"mean\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/30738 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/30738 [00:00<7:55:28,  1.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2/30738 [00:01<8:05:32,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 3/30738 [00:02<7:34:39,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 4/30738 [00:03<7:14:15,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 5/30738 [00:04<7:02:47,  1.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 6/30738 [00:04<6:56:08,  1.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 7/30738 [00:05<6:46:27,  1.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 8/30738 [00:06<7:02:12,  1.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 9/30738 [00:07<7:10:54,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 10/30738 [00:08<7:09:06,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 11/30738 [00:09<7:01:28,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 12/30738 [00:09<7:05:24,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 13/30738 [00:10<7:14:26,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 14/30738 [00:11<7:27:29,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 15/30738 [00:12<7:14:11,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 16/30738 [00:13<7:07:53,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 17/30738 [00:14<7:09:27,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 18/30738 [00:15<7:09:35,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 19/30738 [00:15<7:04:04,  1.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 20/30738 [00:16<7:12:24,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 21/30738 [00:17<7:06:10,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 22/30738 [00:18<7:02:16,  1.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 23/30738 [00:19<6:59:59,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 24/30738 [00:19<6:54:10,  1.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 25/30738 [00:20<6:56:59,  1.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 26/30738 [00:21<7:19:25,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 27/30738 [00:22<7:28:29,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 28/30738 [00:23<7:42:02,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 29/30738 [00:24<7:28:47,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 30/30738 [00:25<7:13:04,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 31/30738 [00:26<7:07:18,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 32/30738 [00:27<7:43:22,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 33/30738 [00:28<8:00:46,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 34/30738 [00:29<7:56:55,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 35/30738 [00:30<8:02:37,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 36/30738 [00:30<8:03:08,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 37/30738 [00:32<7:33:13,  1.13it/s]\u001b[A\u001b[A\n",
      "  0%|          | 0/5 [00:32<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-4bdcbdd2fda2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "loss = 0\n",
    "for epoch in tqdm.tqdm(range(0, num_epochs)):\n",
    "    history = []\n",
    "    for frames in tqdm.tqdm(train_data):\n",
    "        X, y = split_x_y(frames)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(X.float()).double()\n",
    "        \n",
    "        loss = compute_loss(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "history.append(loss.numpy().mean())\n",
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
