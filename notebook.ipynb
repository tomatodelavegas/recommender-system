{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0emZR5b2b4KJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe98645d-5dc7-4b2d-b57c-b1c384178077"
      },
      "source": [
        "RUNNING_IN_COLAB = True\r\n",
        "CALCULATE_NUMPY_ARRAY = True\r\n",
        "\r\n",
        "if RUNNING_IN_COLAB:\r\n",
        "    REPO_URL = 'https://github.com/tomatodelavegas/recommender-system.git'\r\n",
        "    BRANCH   = 'main'\r\n",
        "    REPO_DIR = 'recommender-system'\r\n",
        "    DATA_URL = 'https://drive.google.com/uc?id=1psSrOGsxFrlj0UJH1Gn6Jee4lEVHX69T'\r\n",
        "\r\n",
        "    from pathlib import Path\r\n",
        "\r\n",
        "    %cd /content\r\n",
        "\r\n",
        "    # Download the repository\r\n",
        "    if not Path(REPO_DIR).is_dir():\r\n",
        "        !git clone --branch {BRANCH} --depth=1 -- {REPO_URL} {REPO_DIR}\r\n",
        "    \r\n",
        "    %cd {REPO_DIR}\r\n",
        "\r\n",
        "    # Install requirements\r\n",
        "    !pip install -r requirements.txt | grep -v 'Requirement already satisfied'\r\n",
        "    !pip install gdown | grep -v 'Requirement already satisfied'\r\n",
        "    \r\n",
        "    import gdown\r\n",
        "    if not Path('ml-25m.zip').is_file():\r\n",
        "        gdown.download(DATA_URL, 'ml-25m.zip', quiet=False)\r\n",
        "    \r\n",
        "    if not Path('ml-25m').is_dir():\r\n",
        "        !unzip -q -- ml-25m.zip\r\n",
        "if not CALCULATE_NUMPY_ARRAY:\r\n",
        "  DATA_URL = 'https://drive.google.com/uc?id=1KohLYb76pTLr2hGsPFAUAINr_ZAkPJM_'\r\n",
        "  if not Path('user_frames_divided.npy').is_file():\r\n",
        "    gdown.download(DATA_URL, 'user_frames_divided.npy', quiet=False)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/recommender-system\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noBpsWTQb2KA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfn9sis7rup-"
      },
      "source": [
        "from functools import partial\r\n",
        "from tqdm import tqdm\r\n",
        "tqdm = partial(tqdm, position=0, leave=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydr7jPvGb2KK"
      },
      "source": [
        "# Data\n",
        "First we load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3wE08Pbb2KK"
      },
      "source": [
        "ratings_df = pd.read_csv(\"ml-25m/ratings.csv\")\n",
        "movies_df = pd.read_csv(\"ml-25m/movies.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibBlSvn_b2KL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7fcc757-b529-477c-8605-1b875d44b166"
      },
      "source": [
        "ratings_df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25000095 entries, 0 to 25000094\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Dtype  \n",
            "---  ------     -----  \n",
            " 0   userId     int64  \n",
            " 1   movieId    int64  \n",
            " 2   rating     float64\n",
            " 3   timestamp  int64  \n",
            "dtypes: float64(1), int64(3)\n",
            "memory usage: 762.9 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOPgGYnkb2KM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "13fe57b3-26c7-49d5-ecc1-5119c64ef08f"
      },
      "source": [
        "ratings_df.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1147880044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>306</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1147868817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>307</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1147868828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>665</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1147878820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>899</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1147868510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1088</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1147868495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1175</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1147868826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1217</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1147878326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1237</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1147868839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1250</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1147868414</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1      296     5.0  1147880044\n",
              "1       1      306     3.5  1147868817\n",
              "2       1      307     5.0  1147868828\n",
              "3       1      665     5.0  1147878820\n",
              "4       1      899     3.5  1147868510\n",
              "5       1     1088     4.0  1147868495\n",
              "6       1     1175     3.5  1147868826\n",
              "7       1     1217     3.5  1147878326\n",
              "8       1     1237     5.0  1147868839\n",
              "9       1     1250     4.0  1147868414"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tIxH-_tb2KM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f9029b-6845-4f48-8f4f-eca6de9dad2c"
      },
      "source": [
        "movies_df.info()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 62423 entries, 0 to 62422\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   movieId  62423 non-null  int64 \n",
            " 1   title    62423 non-null  object\n",
            " 2   genres   62423 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 1.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "R0LXThW_scyP",
        "outputId": "55fbef68-4caf-4558-ea1b-047b6cc582a6"
      },
      "source": [
        "movies_df"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62418</th>\n",
              "      <td>209157</td>\n",
              "      <td>We (2018)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62419</th>\n",
              "      <td>209159</td>\n",
              "      <td>Window of the Soul (2001)</td>\n",
              "      <td>Documentary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62420</th>\n",
              "      <td>209163</td>\n",
              "      <td>Bad Poems (2018)</td>\n",
              "      <td>Comedy|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62421</th>\n",
              "      <td>209169</td>\n",
              "      <td>A Girl Thing (2001)</td>\n",
              "      <td>(no genres listed)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62422</th>\n",
              "      <td>209171</td>\n",
              "      <td>Women of Devil's Island (1962)</td>\n",
              "      <td>Action|Adventure|Drama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62423 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       movieId  ...                                       genres\n",
              "0            1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
              "1            2  ...                   Adventure|Children|Fantasy\n",
              "2            3  ...                               Comedy|Romance\n",
              "3            4  ...                         Comedy|Drama|Romance\n",
              "4            5  ...                                       Comedy\n",
              "...        ...  ...                                          ...\n",
              "62418   209157  ...                                        Drama\n",
              "62419   209159  ...                                  Documentary\n",
              "62420   209163  ...                                 Comedy|Drama\n",
              "62421   209169  ...                           (no genres listed)\n",
              "62422   209171  ...                       Action|Adventure|Drama\n",
              "\n",
              "[62423 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLveXhOjb2KN"
      },
      "source": [
        "## Remove Movies without a genre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMzFcXVsb2KN"
      },
      "source": [
        "nogenres_indexes = movies_df.index[movies_df['genres'] == '(no genres listed)'].tolist()\n",
        "movieId_todelete = movies_df.iloc[nogenres_indexes]['movieId'].to_numpy()\n",
        "ratings_df.drop(ratings_df[ratings_df['movieId'].isin(movieId_todelete)].index, inplace=True)\n",
        "ratings_df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvLOd_M4b2KP"
      },
      "source": [
        "#movies_df.drop(index=nogenres_indexes,inplace=True)\n",
        "#movies_df.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9Wg4Emb2KQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b948e915-6d9d-4b3e-84ad-a72176fb7de9"
      },
      "source": [
        "movies_df.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 62423 entries, 0 to 62422\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   movieId  62423 non-null  int64 \n",
            " 1   title    62423 non-null  object\n",
            " 2   genres   62423 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 1.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHNP0nLEb2KS"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31kmculSb2KV"
      },
      "source": [
        "p_genres = {}\n",
        "for e in movies_df.itertuples():\n",
        "    genres_in_row = e[-1].split('|')\n",
        "    for genre in genres_in_row:\n",
        "        if genre in p_genres:\n",
        "            p_genres[genre] += 1\n",
        "        else:\n",
        "            p_genres[genre] = 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h8I361Sb2KZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb5e3ce-3963-4064-d842-1ad8c5410a3b"
      },
      "source": [
        "p_genres"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(no genres listed)': 5062,\n",
              " 'Action': 7348,\n",
              " 'Adventure': 4145,\n",
              " 'Animation': 2929,\n",
              " 'Children': 2935,\n",
              " 'Comedy': 16870,\n",
              " 'Crime': 5319,\n",
              " 'Documentary': 5605,\n",
              " 'Drama': 25606,\n",
              " 'Fantasy': 2731,\n",
              " 'Film-Noir': 353,\n",
              " 'Horror': 5989,\n",
              " 'IMAX': 195,\n",
              " 'Musical': 1054,\n",
              " 'Mystery': 2925,\n",
              " 'Romance': 7719,\n",
              " 'Sci-Fi': 3595,\n",
              " 'Thriller': 8654,\n",
              " 'War': 1874,\n",
              " 'Western': 1399}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7TRsvNB6txv"
      },
      "source": [
        "del p_genres['(no genres listed)']"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xDtXMw66x2a"
      },
      "source": [
        "# One hot encoding index mask for future genre encoding\r\n",
        "one_hot_genres = {}\r\n",
        "index_g = 0\r\n",
        "for key,val in p_genres.items():\r\n",
        "  one_hot_genres[key] = index_g\r\n",
        "  index_g += 1"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlUliKSk7WLL",
        "outputId": "d0754787-8f89-4db6-abb8-806d408ff78c"
      },
      "source": [
        "one_hot_genres"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Action': 7,\n",
              " 'Adventure': 0,\n",
              " 'Animation': 1,\n",
              " 'Children': 2,\n",
              " 'Comedy': 3,\n",
              " 'Crime': 8,\n",
              " 'Documentary': 14,\n",
              " 'Drama': 6,\n",
              " 'Fantasy': 4,\n",
              " 'Film-Noir': 18,\n",
              " 'Horror': 10,\n",
              " 'IMAX': 13,\n",
              " 'Musical': 16,\n",
              " 'Mystery': 11,\n",
              " 'Romance': 5,\n",
              " 'Sci-Fi': 12,\n",
              " 'Thriller': 9,\n",
              " 'War': 15,\n",
              " 'Western': 17}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OFzPODR9DOU",
        "outputId": "2271c3ef-cfb6-4d02-e8e2-71c3d93a933c"
      },
      "source": [
        "movies_df.info()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 62423 entries, 0 to 62422\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   movieId  62423 non-null  int64 \n",
            " 1   title    62423 non-null  object\n",
            " 2   genres   62423 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 1.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kppN7oUj7k-v"
      },
      "source": [
        "movies_hot_encoded_genres = np.zeros((len(movies_df), len(one_hot_genres)))\r\n",
        "for k in movies_df.itertuples(index=True):\r\n",
        "  if k[3] == '(no genres listed)':\r\n",
        "    continue\r\n",
        "  #0 : index, 1: movieId, 2: title, 3: genres\r\n",
        "  # split genres\r\n",
        "  genres_split = k[3].split('|')\r\n",
        "  for genre in genres_split:\r\n",
        "    movies_hot_encoded_genres[k[0], one_hot_genres[genre]] = 1"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "6ND5QCm6-UbR",
        "outputId": "8ecdc586-07e2-4338-d0f6-ed3dece9b739"
      },
      "source": [
        "movies_df.head(1)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieId             title                                       genres\n",
              "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5wXCDb--a4J",
        "outputId": "2eef33e4-67a3-497b-a3f3-306690b78e1c"
      },
      "source": [
        "movies_hot_encoded_genres[0]"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g66XQw98b2Kf"
      },
      "source": [
        "Nous pouvons observer qu'il existe un imbalance en terme de genres de film avec énormement plus de films de Drama que d'autres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjO61-FQb2Ki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae711c4-0b6b-4bb2-fcd4-5d6deb0358e3"
      },
      "source": [
        "user_ids = ratings_df[\"userId\"].unique()\n",
        "nb_user = len(user_ids)\n",
        "nb_user"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "162541"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mofbUV6eb2Kj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c43b9f5-527c-458c-f378-5046955b2b56"
      },
      "source": [
        "import math\n",
        "def divide_ratings():\n",
        "  ratings_by_user_dict = dict(tuple(ratings_df.groupby('userId')))\n",
        "  ratings_by_user = []\n",
        "  for user_id in tqdm(user_ids):\n",
        "      \n",
        "      ratings_of_user = ratings_by_user_dict[user_id]\n",
        "      ratings_of_user.sort_values(by=\"timestamp\", inplace=True, ignore_index=True)\n",
        "      \n",
        "      number_of_ratings = len(ratings_of_user)\n",
        "      ratings_of_user = ratings_of_user.to_numpy()\n",
        "      \n",
        "      # We only keep users with more than 50 ratings\n",
        "      if number_of_ratings >= 50:\n",
        "          \n",
        "          ## We crop to have 25 ratings/frame\n",
        "          if number_of_ratings % 25 != 0:\n",
        "              round_number = number_of_ratings % 25\n",
        "              ratings_of_user = ratings_of_user[:-round_number]\n",
        "              number_of_ratings = ratings_of_user.shape[0]\n",
        "          \n",
        "\n",
        "          dividing_size = number_of_ratings / 25\n",
        "          \n",
        "          user_frames = np.split(ratings_of_user, dividing_size)\n",
        "          \n",
        "          # Remove the user_id of the data and expand dims\n",
        "          ratings_by_user.append(np.expand_dims(np.array(user_frames)[...,1:], axis=-1))\n",
        "\n",
        "  ratings_by_user = np.array(ratings_by_user)\n",
        "  return ratings_by_user\n",
        "\n",
        "ratings_by_user = []\n",
        "if CALCULATE_NUMPY_ARRAY:\n",
        "  ratings_by_user = divide_ratings()\n",
        "else:\n",
        "  ratings_by_user = np.load('user_frames_divided.npy', allow_pickle=True)\n",
        "ratings_by_user.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 162541/162541 [01:40<00:00, 1611.65it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102460,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKOKmELeb2Kk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fa58a00-dbbd-485f-bd3a-254b6b6220f7"
      },
      "source": [
        "len(ratings_by_user)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102460"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0WeGtIcb2Kl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f83a483-49bd-4f37-d87d-678cd793cef1"
      },
      "source": [
        "ratings_by_user[0].shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 25, 3, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e12GI0TIb2Kl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d20024fb-8e4a-4a76-a6f1-9e81368657c5"
      },
      "source": [
        "ratings_by_user[1].shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 25, 3, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb1TmKoDmNTn",
        "outputId": "347ac53b-3922-41b9-f743-2ac3652d87cc"
      },
      "source": [
        "ratings_by_user[0][0,0,:,0]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.95200000e+03, 4.00000000e+00, 1.14786805e+09])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXfbXfwX_dsg"
      },
      "source": [
        "Add the genres encoded channels on the width."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo9Ry1_kb2Km"
      },
      "source": [
        "in_height= ratings_by_user[0].shape[1]\n",
        "in_width= ratings_by_user[0].shape[2] + len(one_hot_genres)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y39b6iBb2Km"
      },
      "source": [
        "if CALCULATE_NUMPY_ARRAY:\r\n",
        "  np.save(\"user_frames_divided.npy\", ratings_by_user)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWHiI2GLb2Km",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f73aedf-de85-4b82-b7ac-d443c4ad7e7a"
      },
      "source": [
        "column_movieId = movies_df[\"movieId\"]\n",
        "print(\"Max ID of movie: \", column_movieId.max())\n",
        "id_list = column_movieId.to_numpy()\n",
        "\n",
        "id_dictionnary = sorted(set(id_list))\n",
        "\n",
        "id_to_index =  {u:i for i, u in enumerate(id_dictionnary)}\n",
        "index_to_id = list(id_dictionnary)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max ID of movie:  209171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE6JJYE4b2Kn"
      },
      "source": [
        "# Model\n",
        "Convolutional Tensor-Train LSTM Recommendation Net  \n",
        "The model was inspired by Covolutional Click Prediction Model (CCPM)  \n",
        " We want to vase our recommendation on previous recommendation we made. We want to add the sequential information  \n",
        "Therefore, we replace the second convolution by a Convolutional Tensor Train LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD28NDweb2Kn"
      },
      "source": [
        "from utils.convlstmnet import ConvLSTMNet\n",
        "from torch.nn import Conv2d, AdaptiveMaxPool2d, Linear, Tanh, ReLU, MaxPool2d, Flatten"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0I5F22Fb2Kn"
      },
      "source": [
        "Hyperparameters for the CTLRN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xubA-Ki5b2Kn"
      },
      "source": [
        "output_size=len(movies_df) # Number of movies\n",
        "inputs_channels=1# To define ==> 2\n",
        "lstm_input_channels=3\n",
        "cell = \"convttlstm\"\n",
        "order = 3\n",
        "steps = 3\n",
        "rank = 8\n",
        "kernel_size = 5\n",
        "lr=1e-3\n",
        "output_sigmoid = True"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hjXP57Eb2Ko"
      },
      "source": [
        "padding_size_w=in_height//2\n",
        "padding_size_h=in_width//2"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe-OBcQ8b2Ko"
      },
      "source": [
        "ctln_model = ConvLSTMNet(\n",
        "        # input to the model\n",
        "        input_channels = lstm_input_channels, \n",
        "        # architecture of the model\n",
        "        layers_per_block = (3, 3, 3, 3), \n",
        "        hidden_channels = (32, 48, 48, 32), \n",
        "        skip_stride = 2,\n",
        "        # parameters of convolutional tensor-train layers\n",
        "        cell = cell, cell_params = {\"order\": order,\n",
        "        \"steps\": steps, \"rank\": rank},\n",
        "        # parameters of convolutional operations\n",
        "        kernel_size = kernel_size, bias = True,\n",
        "        # output function and output format\n",
        "        output_sigmoid = output_sigmoid)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNxmIMqlb2Ko"
      },
      "source": [
        "class CTLRNet(nn.Module):\n",
        "    def __init__(self, inputs_channels, output_size):\n",
        "        super(CTLRNet, self).__init__()\n",
        "        \n",
        "        self.inputs_channels = inputs_channels\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.conv1 = Conv2d(in_channels=inputs_channels, out_channels=lstm_input_channels,\n",
        "                       padding=(padding_size_h,padding_size_h), kernel_size=(3,3))\n",
        "        self.pool1 = AdaptiveMaxPool2d(output_size=(in_height, in_width))\n",
        "        self.tanh = Tanh()\n",
        "        self.convttlstm = ctln_model # Espace latent \n",
        "        self.pool2 = MaxPool2d(2) # Padding ?\n",
        "        self.flatten = Flatten()\n",
        "        self.linear = Linear(in_features=396, out_features=output_size) # 62000\n",
        "        self.relu = ReLU()\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.pool1(x)\n",
        "        x = self.tanh(x)\n",
        "        \n",
        "        ## To study exactly\n",
        "        ## uwu ?\n",
        "        x = torch.unsqueeze(x, dim=0)\n",
        "        x = self.convttlstm(x, input_frames = inputs.shape[1], future_frames = 1, output_frames = 1)\n",
        "        x = torch.squeeze(x, dim=0)\n",
        "        \n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear(x)\n",
        "        y = self.relu(x)\n",
        "        return y\n",
        "        "
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00gJem_fb2Kp"
      },
      "source": [
        "model = CTLRNet(inputs_channels, output_size)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96MwYHPY_973"
      },
      "source": [
        "quick_test_data = ratings_by_user[0]"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au0xaFPDDZlM"
      },
      "source": [
        "def add_movies_hot_encoding(data):\r\n",
        "  new_data = [ \r\n",
        "              [ \r\n",
        "               movies_hot_encoded_genres[id_to_index[rating[0,0]]] \r\n",
        "              for rating in frame ] \r\n",
        "             for frame in quick_test_data ]\r\n",
        "  return np.concatenate((quick_test_data, np.expand_dims(np.array(new_data),axis=-1)), axis=2)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK5QqqHyK3Eu"
      },
      "source": [
        "quick_test_data_c = add_movies_hot_encoding(quick_test_data)"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXnOvMVAMGch"
      },
      "source": [
        "quick_test_data_c = torch.from_numpy(quick_test_data_c).permute([0,3,1,2])"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "griti-yyb2Kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52fa6731-87b1-41fc-f901-dafc579043b2"
      },
      "source": [
        "quick_test_data_c.shape"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1, 25, 22])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2KGqFvDb2Kp"
      },
      "source": [
        "r = model(quick_test_data_c.float())"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaXIQAGwokzO",
        "outputId": "f6aa0ab8-1142-4b22-f318-f093a870d5f0"
      },
      "source": [
        "r, r.shape"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.3230, 0.0000, 0.1834,  ..., 0.3393, 0.0313, 0.1690]],\n",
              "        grad_fn=<ReluBackward0>), torch.Size([1, 62423]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-McfPU3cMj-x",
        "outputId": "d9ac5be1-0e1d-422e-da82-1f6621dc227d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "quick_test_data_c[0,0,0]"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.5247e+04, 5.0000e+00, 1.4531e+09, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMlwCsapb2Kq"
      },
      "source": [
        "## Data Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znb2j5tk-yfF"
      },
      "source": [
        "To avoid overwhelming the RAM we will only had the one hot encoded genres information at runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPXn1CPzb2Kq"
      },
      "source": [
        "np.random.shuffle(ratings_by_user)\n",
        "\n",
        "data_samples = ratings_by_user.shape[0]\n",
        "\n",
        "train_size = math.ceil(data_samples * 0.70)\n",
        "test_size = data_samples - train_size\n",
        "\n",
        "train_data = ratings_by_user[:train_size][:5000]\n",
        "test_data = ratings_by_user[train_size:][:1000]"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKjzV2Hhu5pd",
        "outputId": "d5a116a7-d83e-4685-9593-15f283eff968"
      },
      "source": [
        "len(train_data),len(test_data)"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tlhEVZyb2Kq"
      },
      "source": [
        "def split_x_y(data, p=0.25):\n",
        "    \"\"\"\n",
        "    Split and construct a frame into an input and an output\n",
        "    parameters data: (nb_frames, c, h, w0)\n",
        "    return: (nb_frames, c, h, w0), (nb_movies)\n",
        "    \"\"\"\n",
        "    data_frames = data.shape[0]\n",
        "    X_size = math.floor(data_frames * (1-p))\n",
        "    Y_data_size = data_frames - X_size\n",
        "    \n",
        "    \n",
        "    X = data[:X_size]\n",
        "    Y_data = data[Y_data_size:]\n",
        "    \n",
        "    y = np.zeros(output_size)\n",
        "    \n",
        "    #print()\n",
        "    \n",
        "    #y[Y_data[...,1]] = Y_data[...,2]\n",
        "    # Make sure!\n",
        "    # row[0] = movieId\n",
        "    # row[1] = rating\n",
        "    #print(Y_data)\n",
        "    for frame in Y_data:\n",
        "        for row in frame[0]:\n",
        "            y[id_to_index[int(row[0])]] = row[1]\n",
        "    \n",
        "    return X, torch.from_numpy(y.reshape(1,-1)).double()\n",
        "            "
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAH8aYv2qRj1"
      },
      "source": [
        "x_test, y_test = split_x_y(quick_test_data_c)"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv8-gzp0qbKr",
        "outputId": "16af6af2-b8d2-455d-daac-9a60a9372c3e"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 25, 22])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5A13jRiqcvM",
        "outputId": "7eb036fc-5194-4eb8-9d77-99e3dd37668c"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 62423])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAXx3ZFZrYsu",
        "outputId": "063e8929-5a48-4cbb-bb47-7fcae94db10d"
      },
      "source": [
        "id_to_index[7365]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7240"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKAxrV8squLa",
        "outputId": "f6007774-690b-4627-a787-cac69e7efe08"
      },
      "source": [
        "y_test[0, id_to_index[7365]]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4., dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAM-nfaSwjFj"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSVIvSPwb2Ks"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_loss(y_pred, y_true):\n",
        "    return F.l1_loss(y_pred, y_true, reduction = \"mean\") + F.mse_loss(y_pred, y_true, reduction = \"mean\")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf3RgzV5f9-V"
      },
      "source": [
        "# whether to use GPU (or CPU) \r\n",
        "use_cuda  = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\r\n",
        "\r\n",
        "# whether to use multi-GPU (or single-GPU)\r\n",
        "multi_gpu = use_cuda and torch.cuda.device_count() > 1\r\n",
        "num_gpus = (torch.cuda.device_count() if multi_gpu else 1) if use_cuda else 0\r\n",
        "# move the model to the device (CPU, GPU, multi-GPU) \r\n",
        "model.to(device)\r\n",
        "if multi_gpu: \r\n",
        "    model = nn.DataParallel(model)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-c1SK7zb2Ks",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "79d09ada-e39d-4427-a816-2d54327b7632"
      },
      "source": [
        "# Training loop\n",
        "num_epochs = 5\n",
        "\n",
        "loss = 0\n",
        "for epoch in range(0, num_epochs):\n",
        "    history = []\n",
        "    loop = tqdm(enumerate(train_data), total = len(train_data))\n",
        "    for batch_idx, frames in loop:\n",
        "      frames = add_movies_hot_encoding(frames)\n",
        "      frames = torch.from_numpy(frames).permute([0,3,1,2]).to(device)\n",
        "      X, y = split_x_y(frames)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      pred = model(X.float()).double().to(device)\n",
        "      y = y.to(device)\n",
        "      loss = compute_loss(pred, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      loop.set_description(f\"Epoch [{epoch}/{num_epochs}]\")\n",
        "      loop.set_postfix(loss= loss.item())\n",
        "      history.append(loss.mean())\n",
        "\n",
        "torch.save(model.state_dict(), \"checkpoint.pt\")\n",
        "plt.plot(history)"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/5]:   1%|          | 71/10000 [00:57<2:05:58,  1.31it/s, loss=0.0073]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-205-424ca0781fdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbJgdsOJwsbG"
      },
      "source": [
        "# Recommender\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtb4Xhg3wv0N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}