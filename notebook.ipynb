{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "First we load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"ml-25m/ratings.csv\")\n",
    "movies_df = pd.read_csv(\"ml-25m/movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Movies without a genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nogenres_indexes = movies_df.index[movies_df['genres'] == '(no genres listed)'].tolist()\n",
    "movieId_todelete = movies_df.iloc[nogenres_indexes]['movieId'].to_numpy()\n",
    "ratings_df.drop(ratings_df[ratings_df['movieId'].isin(movieId_todelete)].index, inplace=True)\n",
    "ratings_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.drop(index=nogenres_indexes,inplace=True)\n",
    "movies_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_genres = {}\n",
    "for e in movies_df.itertuples():\n",
    "    genres_in_row = e[-1].split('|')\n",
    "    for genre in genres_in_row:\n",
    "        if genre in p_genres:\n",
    "            p_genres[genre] += 1\n",
    "        else:\n",
    "            p_genres[genre] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_genres"
   ]
  },
  {
   "source": [
    "Nous pouvons observer qu'il existe un imbalance en terme de genres de film avec Ã©normement plus de films de Drama que d'autres."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = ratings_df[\"userId\"].unique()\n",
    "nb_user = len(user_ids)\n",
    "nb_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_by_user_dict = dict(tuple(ratings_df.groupby('userId')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "ratings_by_user = []\n",
    "for user_id in tqdm.tqdm(user_ids):\n",
    "    \n",
    "    ratings_of_user = ratings_by_user_dict[user_id]\n",
    "    ratings_of_user.sort_values(by=\"timestamp\", inplace=True, ignore_index=True)\n",
    "    \n",
    "    number_of_ratings = len(ratings_of_user)\n",
    "    ratings_of_user = ratings_of_user.to_numpy()\n",
    "    \n",
    "    # We only keep users with more than 50 ratings\n",
    "    if number_of_ratings >= 50:\n",
    "        \n",
    "        ## We crop to have 25 ratings/frame\n",
    "        if number_of_ratings % 25 != 0:\n",
    "            round_number = number_of_ratings % 25\n",
    "            ratings_of_user = ratings_of_user[:-round_number]\n",
    "            number_of_ratings = ratings_of_user.shape[0]\n",
    "        \n",
    "\n",
    "        dividing_size = number_of_ratings / 25\n",
    "        \n",
    "        user_frames = np.split(ratings_of_user, dividing_size)\n",
    "        \n",
    "        ratings_by_user.append(np.expand_dims(np.array(user_frames), axis=-1))\n",
    "\n",
    "ratings_by_user = np.array(ratings_by_user)\n",
    "    \n",
    "ratings_by_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ratings_by_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_by_user[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_by_user[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_height=ratings_by_user[0].shape[1]\n",
    "in_width=ratings_by_user[0].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"user_frames_divided.npy\", ratings_by_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Convolutional Tensor-Train LSTM Recommendation Net  \n",
    "The model was inspired by Covolutional Click Prediction Model (CCPM)  \n",
    " We want to vase our recommendation on previous recommendation we made. We want to add the sequential information  \n",
    "Therefore, we replace the second convolution by a Convolutional Tensor Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.convlstmnet import ConvLSTMNet\n",
    "from torch.nn import Conv2d, AdaptiveMaxPool2d, Linear, Tanh, ReLU, MaxPool2d, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters for the CTLRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size=10 # Number of movies\n",
    "inputs_channels=1# To define ==> 2\n",
    "lstm_input_channels=3\n",
    "cell = \"convttlstm\"\n",
    "order = 3\n",
    "steps = 3\n",
    "rank = 8\n",
    "kernel_size = 5\n",
    "output_sigmoid = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_size_w=in_height//2\n",
    "padding_size_h=in_width//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctln_model = ConvLSTMNet(\n",
    "        # input to the model\n",
    "        input_channels = lstm_input_channels, \n",
    "        # architecture of the model\n",
    "        layers_per_block = (3, 3, 3, 3), \n",
    "        hidden_channels = (32, 48, 48, 32), \n",
    "        skip_stride = 2,\n",
    "        # parameters of convolutional tensor-train layers\n",
    "        cell = cell, cell_params = {\"order\": order,\n",
    "        \"steps\": steps, \"rank\": rank},\n",
    "        # parameters of convolutional operations\n",
    "        kernel_size = kernel_size, bias = True,\n",
    "        # output function and output format\n",
    "        output_sigmoid = output_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTLRNet(nn.Module):\n",
    "    def __init__(self, inputs_channels, output_size):\n",
    "        super(CTLRNet, self).__init__()\n",
    "        \n",
    "        self.inputs_channels = inputs_channels\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.conv1 = Conv2d(in_channels=inputs_channels, out_channels=lstm_input_channels,\n",
    "                       padding=(padding_size_h,padding_size_h), kernel_size=(3,3))\n",
    "        self.pool1 = AdaptiveMaxPool2d(output_size=(in_height, in_width))\n",
    "        self.tanh = Tanh()\n",
    "        self.convttlstm = ctln_model\n",
    "        self.pool2 = MaxPool2d(2) # Padding ?\n",
    "        self.flatten = Flatten()\n",
    "        self.linear = Linear(in_features=72, out_features=output_size)\n",
    "        self.relu = ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.tanh(x)\n",
    "        \n",
    "        ## To study exactly\n",
    "        ## uwu ?\n",
    "        x = torch.unsqueeze(x, dim=0)\n",
    "        x = self.convttlstm(x, input_frames = inputs.shape[1], future_frames = 1, output_frames = 1)\n",
    "        x = torch.squeeze(x, dim=0)\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        y = self.relu(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CTLRNet(inputs_channels, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_test_data = torch.from_numpy(np.expand_dims(ratings_by_user[0], axis=-1)).permute([0,3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(quick_test_data.float()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(ratings_by_user)\n",
    "\n",
    "data_samples = ratings_by_user.shape[0]\n",
    "\n",
    "train_size = math.ceil(data_samples * 0.70)\n",
    "test_size = data_samples - train_size\n",
    "\n",
    "train_data = ratings_by_user[train_size:]\n",
    "test_data = ratings_by_user[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}