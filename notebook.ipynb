{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0emZR5b2b4KJ"
      },
      "source": [
        "RUNNING_IN_COLAB = True\r\n",
        "CALCULATE_NUMPY_ARRAY = False\r\n",
        "\r\n",
        "if RUNNING_IN_COLAB:\r\n",
        "    REPO_URL = 'https://github.com/tomatodelavegas/recommender-system.git'\r\n",
        "    BRANCH   = 'main'\r\n",
        "    REPO_DIR = 'recommender-system'\r\n",
        "    DATA_URL = 'https://drive.google.com/uc?id=1psSrOGsxFrlj0UJH1Gn6Jee4lEVHX69T'\r\n",
        "\r\n",
        "    from pathlib import Path\r\n",
        "\r\n",
        "    %cd /content\r\n",
        "\r\n",
        "    # Download the repository\r\n",
        "    if not Path(REPO_DIR).is_dir():\r\n",
        "        !git clone --branch {BRANCH} --depth=1 -- {REPO_URL} {REPO_DIR}\r\n",
        "    \r\n",
        "    %cd {REPO_DIR}\r\n",
        "\r\n",
        "    # Install requirements\r\n",
        "    !pip install -r requirements.txt | grep -v 'Requirement already satisfied'\r\n",
        "    !pip install gdown | grep -v 'Requirement already satisfied'\r\n",
        "    \r\n",
        "    import gdown\r\n",
        "    if not Path('ml-25m.zip').is_file():\r\n",
        "        gdown.download(DATA_URL, 'ml-25m.zip', quiet=False)\r\n",
        "    \r\n",
        "    if not Path('ml-25m').is_dir():\r\n",
        "        !unzip -q -- ml-25m.zip\r\n",
        "if not CALCULATE_NUMPY_ARRAY:\r\n",
        "  DATA_URL = 'https://drive.google.com/uc?id=1KohLYb76pTLr2hGsPFAUAINr_ZAkPJM_'\r\n",
        "  if not Path('user_frames_divided.npy').is_file():\r\n",
        "    gdown.download(DATA_URL, 'user_frames_divided.npy', quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noBpsWTQb2KA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfn9sis7rup-"
      },
      "source": [
        "from functools import partial\r\n",
        "from tqdm import tqdm\r\n",
        "tqdm = partial(tqdm, position=0, leave=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydr7jPvGb2KK"
      },
      "source": [
        "# Data\n",
        "First we load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3wE08Pbb2KK"
      },
      "source": [
        "ratings_df = pd.read_csv(\"ml-25m/ratings.csv\")\n",
        "movies_df = pd.read_csv(\"ml-25m/movies.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibBlSvn_b2KL"
      },
      "source": [
        "ratings_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOPgGYnkb2KM"
      },
      "source": [
        "ratings_df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tIxH-_tb2KM"
      },
      "source": [
        "movies_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLveXhOjb2KN"
      },
      "source": [
        "## Remove Movies without a genre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMzFcXVsb2KN"
      },
      "source": [
        "nogenres_indexes = movies_df.index[movies_df['genres'] == '(no genres listed)'].tolist()\n",
        "movieId_todelete = movies_df.iloc[nogenres_indexes]['movieId'].to_numpy()\n",
        "ratings_df.drop(ratings_df[ratings_df['movieId'].isin(movieId_todelete)].index, inplace=True)\n",
        "ratings_df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvLOd_M4b2KP"
      },
      "source": [
        "#movies_df.drop(index=nogenres_indexes,inplace=True)\n",
        "#movies_df.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9Wg4Emb2KQ"
      },
      "source": [
        "movies_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHNP0nLEb2KS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31kmculSb2KV"
      },
      "source": [
        "p_genres = {}\n",
        "for e in movies_df.itertuples():\n",
        "    genres_in_row = e[-1].split('|')\n",
        "    for genre in genres_in_row:\n",
        "        if genre in p_genres:\n",
        "            p_genres[genre] += 1\n",
        "        else:\n",
        "            p_genres[genre] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h8I361Sb2KZ"
      },
      "source": [
        "p_genres"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g66XQw98b2Kf"
      },
      "source": [
        "Nous pouvons observer qu'il existe un imbalance en terme de genres de film avec Ã©normement plus de films de Drama que d'autres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjO61-FQb2Ki"
      },
      "source": [
        "user_ids = ratings_df[\"userId\"].unique()\n",
        "nb_user = len(user_ids)\n",
        "nb_user"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQN2STPQb2Kj"
      },
      "source": [
        "ratings_by_user_dict = dict(tuple(ratings_df.groupby('userId')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mofbUV6eb2Kj"
      },
      "source": [
        "import math\n",
        "def divide_ratings():\n",
        "  ratings_by_user = []\n",
        "  for user_id in tqdm.tqdm(user_ids):\n",
        "      \n",
        "      ratings_of_user = ratings_by_user_dict[user_id]\n",
        "      ratings_of_user.sort_values(by=\"timestamp\", inplace=True, ignore_index=True)\n",
        "      \n",
        "      number_of_ratings = len(ratings_of_user)\n",
        "      ratings_of_user = ratings_of_user.to_numpy()\n",
        "      \n",
        "      # We only keep users with more than 50 ratings\n",
        "      if number_of_ratings >= 50:\n",
        "          \n",
        "          ## We crop to have 25 ratings/frame\n",
        "          if number_of_ratings % 25 != 0:\n",
        "              round_number = number_of_ratings % 25\n",
        "              ratings_of_user = ratings_of_user[:-round_number]\n",
        "              number_of_ratings = ratings_of_user.shape[0]\n",
        "          \n",
        "\n",
        "          dividing_size = number_of_ratings / 25\n",
        "          \n",
        "          user_frames = np.split(ratings_of_user, dividing_size)\n",
        "          \n",
        "          ratings_by_user.append(np.expand_dims(np.array(user_frames), axis=-1))\n",
        "\n",
        "  ratings_by_user = np.array(ratings_by_user)\n",
        "  return ratings_by_user\n",
        "\n",
        "ratings_by_user = []\n",
        "if CALCULATE_NUMPY_ARRAY:\n",
        "  ratings_by_user = divide_ratings()\n",
        "else:\n",
        "  ratings_by_user = np.load('user_frames_divided.npy', allow_pickle=True)\n",
        "ratings_by_user.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKOKmELeb2Kk"
      },
      "source": [
        "len(ratings_by_user)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0WeGtIcb2Kl"
      },
      "source": [
        "ratings_by_user[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e12GI0TIb2Kl"
      },
      "source": [
        "ratings_by_user[1].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo9Ry1_kb2Km"
      },
      "source": [
        "in_height=ratings_by_user[0].shape[1]\n",
        "in_width=ratings_by_user[0].shape[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y39b6iBb2Km"
      },
      "source": [
        "if CALCULATE_NUMPY_ARRAY:\r\n",
        "  np.save(\"user_frames_divided.npy\", ratings_by_user)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWHiI2GLb2Km"
      },
      "source": [
        "column_movieId = movies_df[\"movieId\"]\n",
        "print(\"Max ID of movie: \", column_movieId.max())\n",
        "id_list = column_movieId.to_numpy()\n",
        "\n",
        "id_dictionnary = sorted(set(id_list))\n",
        "\n",
        "id_to_index =  {u:i for i, u in enumerate(id_dictionnary)}\n",
        "index_to_id = list(id_dictionnary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE6JJYE4b2Kn"
      },
      "source": [
        "# Model\n",
        "Convolutional Tensor-Train LSTM Recommendation Net  \n",
        "The model was inspired by Covolutional Click Prediction Model (CCPM)  \n",
        " We want to vase our recommendation on previous recommendation we made. We want to add the sequential information  \n",
        "Therefore, we replace the second convolution by a Convolutional Tensor Train LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD28NDweb2Kn"
      },
      "source": [
        "from utils.convlstmnet import ConvLSTMNet\n",
        "from torch.nn import Conv2d, AdaptiveMaxPool2d, Linear, Tanh, ReLU, MaxPool2d, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0I5F22Fb2Kn"
      },
      "source": [
        "Hyperparameters for the CTLRN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xubA-Ki5b2Kn"
      },
      "source": [
        "output_size=len(movies_df) # Number of movies\n",
        "inputs_channels=1# To define ==> 2\n",
        "lstm_input_channels=3\n",
        "cell = \"convttlstm\"\n",
        "order = 3\n",
        "steps = 3\n",
        "rank = 8\n",
        "kernel_size = 5\n",
        "lr=1e-3\n",
        "output_sigmoid = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hjXP57Eb2Ko"
      },
      "source": [
        "padding_size_w=in_height//2\n",
        "padding_size_h=in_width//2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe-OBcQ8b2Ko"
      },
      "source": [
        "ctln_model = ConvLSTMNet(\n",
        "        # input to the model\n",
        "        input_channels = lstm_input_channels, \n",
        "        # architecture of the model\n",
        "        layers_per_block = (3, 3, 3, 3), \n",
        "        hidden_channels = (32, 48, 48, 32), \n",
        "        skip_stride = 2,\n",
        "        # parameters of convolutional tensor-train layers\n",
        "        cell = cell, cell_params = {\"order\": order,\n",
        "        \"steps\": steps, \"rank\": rank},\n",
        "        # parameters of convolutional operations\n",
        "        kernel_size = kernel_size, bias = True,\n",
        "        # output function and output format\n",
        "        output_sigmoid = output_sigmoid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNxmIMqlb2Ko"
      },
      "source": [
        "class CTLRNet(nn.Module):\n",
        "    def __init__(self, inputs_channels, output_size):\n",
        "        super(CTLRNet, self).__init__()\n",
        "        \n",
        "        self.inputs_channels = inputs_channels\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.conv1 = Conv2d(in_channels=inputs_channels, out_channels=lstm_input_channels,\n",
        "                       padding=(padding_size_h,padding_size_h), kernel_size=(3,3))\n",
        "        self.pool1 = AdaptiveMaxPool2d(output_size=(in_height, in_width))\n",
        "        self.tanh = Tanh()\n",
        "        self.convttlstm = ctln_model\n",
        "        self.pool2 = MaxPool2d(2) # Padding ?\n",
        "        self.flatten = Flatten()\n",
        "        self.linear = Linear(in_features=72, out_features=output_size)\n",
        "        self.relu = ReLU()\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.pool1(x)\n",
        "        x = self.tanh(x)\n",
        "        \n",
        "        ## To study exactly\n",
        "        ## uwu ?\n",
        "        x = torch.unsqueeze(x, dim=0)\n",
        "        x = self.convttlstm(x, input_frames = inputs.shape[1], future_frames = 1, output_frames = 1)\n",
        "        x = torch.squeeze(x, dim=0)\n",
        "        \n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear(x)\n",
        "        y = self.relu(x)\n",
        "        return x\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00gJem_fb2Kp"
      },
      "source": [
        "model = CTLRNet(inputs_channels, output_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b67uoEhUb2Kp"
      },
      "source": [
        "quick_test_data = torch.from_numpy(ratings_by_user[0]).permute([0,3,1,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "griti-yyb2Kp"
      },
      "source": [
        "quick_test_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2KGqFvDb2Kp"
      },
      "source": [
        "model(quick_test_data.float()).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMlwCsapb2Kq"
      },
      "source": [
        "## Data Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPXn1CPzb2Kq"
      },
      "source": [
        "np.random.shuffle(ratings_by_user)\n",
        "\n",
        "data_samples = ratings_by_user.shape[0]\n",
        "\n",
        "train_size = math.ceil(data_samples * 0.70)\n",
        "test_size = data_samples - train_size\n",
        "\n",
        "train_data = ratings_by_user[train_size:]\n",
        "test_data = ratings_by_user[:test_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tlhEVZyb2Kq"
      },
      "source": [
        "def split_x_y(data, p=0.25):\n",
        "    \"\"\"\n",
        "    Split and construct a frame into an input and an output\n",
        "    parameters data: (nb_frames, c, h, w0)\n",
        "    return: (nb_frames, c, h, w0), (nb_movies)\n",
        "    \"\"\"\n",
        "    data_frames = data.shape[0]\n",
        "    X_size = math.ceil(data_frames * (1-p))\n",
        "    Y_data_size = data_frames - X_size\n",
        "    \n",
        "    \n",
        "    X = data[:X_size]\n",
        "    Y_data = data[Y_data_size:]\n",
        "    \n",
        "    y = np.zeros(output_size)\n",
        "    \n",
        "    #print()\n",
        "    \n",
        "    #y[Y_data[...,1]] = Y_data[...,2]\n",
        "    \n",
        "    for frame in Y_data:\n",
        "        for row in frame[0]:\n",
        "            y[id_to_index[int(row[1])]] = row[2]\n",
        "    \n",
        "    return X, torch.from_numpy(y.reshape(1,-1)).double()\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSVIvSPwb2Ks"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_loss(y_pred, y_true):\n",
        "    return F.l1_loss(y_pred, y_true, reduction = \"mean\") + F.mse_loss(y_pred, y_true, reduction = \"mean\")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf3RgzV5f9-V"
      },
      "source": [
        "# whether to use GPU (or CPU) \r\n",
        "use_cuda  = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\r\n",
        "\r\n",
        "# whether to use multi-GPU (or single-GPU)\r\n",
        "multi_gpu = use_cuda and torch.cuda.device_count() > 1\r\n",
        "num_gpus = (torch.cuda.device_count() if multi_gpu else 1) if use_cuda else 0\r\n",
        "# move the model to the device (CPU, GPU, multi-GPU) \r\n",
        "model.to(device)\r\n",
        "if multi_gpu: \r\n",
        "    model = nn.DataParallel(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-c1SK7zb2Ks"
      },
      "source": [
        "# Training loop\n",
        "num_epochs = 5\n",
        "\n",
        "loss = 0\n",
        "for epoch in range(0, num_epochs):\n",
        "    history = []\n",
        "    loop = tqdm(enumerate(train_data), total = len(train_data))\n",
        "    for batch_idx, frames in loop:\n",
        "      frames = torch.from_numpy(frames).permute([0,3,1,2]).to(device)\n",
        "      X, y = split_x_y(frames)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      pred = model(X.float()).double().to(device)\n",
        "      y = y.to(device)\n",
        "      loss = compute_loss(pred, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      loop.set_description(f\"Epoch [{epoch}/{num_epochs}]\")\n",
        "      loop.set_postfix(loss= loss.item())\n",
        "\n",
        "\n",
        "history.append(loss.numpy().mean())\n",
        "plt.plot(history)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}